# -*- coding: utf-8 -*-
"""Lab3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gIm9ixARD8T-zt2lJJT9X-tZs9vOnPoW
"""

import numpy as np
from matplotlib import pyplot as plt
from scipy.stats import truncnorm
import pandas as pd
import seaborn as sns
from scipy.stats import t
import math


#small value to avoid divisions by 0 when std_e or std_s assume this value
eps = 1e-30

def Peergrading_simulation(H, S, K, std_s, std_e, seed, output = False, verbose = False, return_acc= False):
  
  #fix the random seed
  np.random.seed(seed)

  #Initialization phase

  #sample S students quality from a uniform distribution with support [0,1]
  X = np.random.uniform(size = S)

  #Delivery phase
  Q = np.empty(shape = (H,S))
  for s, x in enumerate(X):
    #generating the extremes to insert in stats.truncnorm in order to get a truncate normal with support [0,1]
    a, b = (0 - x) / (std_s + eps), (1 - x) / (std_s + eps)
    #sample H values from the truncated norm: these are the homework qualities
    Q[:, s] = truncnorm(a, b, loc = x, scale = std_s).rvs(H)

  #Evaluation phase
  E = np.empty(shape = (H,S,K))
  for h in range(H):
    for s in range(S):
      #generating the extremes to insert in stats.truncnorm in order to get a truncate normal with support [0,1]
      a, b = (0 - Q[h, s]) / (std_e + eps), (1 - Q[h, s]) / (std_e + eps)
      #sample K values from the truncated norm: these are the homework evaluations
      E[h, s, :] = truncnorm(a, b, loc = Q[h, s], scale = std_e).rvs(K)
  
  #average on the evaluations
  Q_estimated = E.mean(axis = 2)

  #Accuracy computation
  rel_err = np.sum(np.abs(Q_estimated - Q), axis = 0)/np.sum(Q, axis = 0)
  avg_rel_err = np.mean(rel_err)
  acc = 1 - avg_rel_err
  
  #Saving results
  if output:
    stats = pd.DataFrame([[acc, H, S, K, std_s, std_e, seed]])
    stats.to_csv(output, index=False, header = False, mode='a', sep = " ")

  if verbose:
    print("Accuracy: ", acc)
    print(H, S, K, std_s, std_e, seed)
  
  if return_acc:
    return acc

#define inputs 
Hs = [2, 5, 10, 15, 20]
Ss = [2, 4, 8, 16, 32, 64]
Ks = [2, 4, 8, 16, 32, 64]
STD_S = [0, 0.01, 0.05, 0.1, 0.2, 1e10]
STD_E = [0, 0.01, 0.05, 0.1, 0.2, 1e10]
SEED = range(2, 8)

# #Simulation
# for S in Ss:
#   for H in Hs:
#     for K in Ks:
#       for std_s in STD_S:
#         for std_e in STD_E:
#           for seed in SEED:
#            Peergrading_simulation(H, S, K, std_s, std_e, seed, output= "./stats_updated.csv")

#importing dataframe with accuracy for each run
stats = pd.read_csv('./stats_updated.csv', sep=' ', 
                    names = ["Accuracy", "Number of homeworks", "Number of students", "Number of evaluators", "Homework quality std", "Evaluation std", "Seed"])
attributes = ["Number of homeworks", "Number of students", "Number of evaluators", "Homework quality std", "Evaluation std"]

#averaging accuracy over runs with different seeds
avg_stats = stats\
.drop(columns= ["Seed"])\
.groupby(attributes)\
.mean()\
.reset_index()

#computing sample std of accuracy over runs with different seeds
avg_stats["Accuracy std"] = stats\
.drop(columns= ["Seed"])\
.groupby(attributes)\
.std(ddof = 1).values

#Computing correlation matrix and slicing it
# to highlight only correlations between inputs and accuracy avg and std
corr = avg_stats.corr().iloc[:, -2:]
#Plotting correlation coefficients
plt.figure(figsize=(12,12))
sns.heatmap(corr, annot=True, square=True, cmap='coolwarm')
plt.savefig('Correlation.png', bbox_inches='tight')

#Plotting boxplots of the accuracy with respect to different values of the attributes

fig, ax = plt.subplots(1,3, figsize = (25, 10), sharey=True)
for i, attribute in enumerate(["Number of homeworks", "Number of students", "Number of evaluators"]):

  
  ax[i].grid()
  sns.boxplot(x= attribute, y = "Accuracy",
            data= avg_stats, ax=ax[i])
  
plt.savefig('Number boxplots for Acc.png', bbox_inches='tight')


fig, ax = plt.subplots(1,2, figsize = (20, 8), sharey=True)
for i, attribute in enumerate(["Homework quality std", "Evaluation std"]):
  ax[i].grid()
  sns.boxplot(x= attribute, y = "Accuracy",
            data= avg_stats, ax=ax[i])

plt.savefig('Std boxplots for Acc.png', bbox_inches='tight')

#Plotting boxplots of the accuracy std with respect to different values of the attributes

fig, ax = plt.subplots(1,3, figsize = (25, 10), sharey=True)
for i, attribute in enumerate(["Number of homeworks", "Number of students", "Number of evaluators"]):

  ax[i].grid()
  sns.boxplot(x= attribute, y = "Accuracy std",
            data= avg_stats, ax=ax[i])

plt.savefig('Number boxplots for Acc std.png', bbox_inches='tight')

fig, ax = plt.subplots(1,2, figsize = (20, 8), sharey=True)
for i, attribute in enumerate(["Homework quality std", "Evaluation std"]):
  ax[i].grid()
  sns.boxplot(x= attribute, y = "Accuracy std",
            data= avg_stats, ax=ax[i])

plt.savefig('Std boxplots for Acc Std.png', bbox_inches='tight')


colors = ["orange", "red", "blue", "green" , "black"] 

fig, ax = plt.subplots(2, 3, figsize = (18, 10), sharey = True, sharex = True)
#Creating a graph for every "number of students" value
for i, S in enumerate(Ss):
  ax[i//3, i%3].set_xlabel("Number of evaluators")
  ax[i//3, i%3].set_ylabel("Accuracy")
  ax[i//3, i%3].set_title("Number of students: " +str(S))
  ax[i//3, i%3].grid()
  #plotting a curve for every "number of homeworks" value
  for c, H in zip(colors, Hs):
    #selecting only the part of the dataframe with the fixed values
    acc_by_evaluators = avg_stats.loc[(avg_stats["Number of homeworks"] == H) \
              & (avg_stats["Number of students"] == S) \
              & (avg_stats["Homework quality std"] == 0.1) \
              &(avg_stats["Evaluation std"] == 0.1), ["Accuracy"]]
    #plotting accuracy w.r.t. thw number of evaluators
    ax[i//3, i%3].plot(Ks, acc_by_evaluators, "*-", c = c, label = "num homeworks: " + str(H))

plt.legend(loc = 4)
plt.tight_layout()
plt.savefig('OthAttributes.png', bbox_inches='tight')